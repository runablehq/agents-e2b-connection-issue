import { routeAgentRequest, type Connection, type WSMessage } from "agents";

import { unstable_getSchedulePrompt } from "agents/schedule";

import { openai } from "@ai-sdk/openai";
import { Sandbox } from "@e2b/desktop";
import { AIChatAgent } from "agents/ai-chat-agent";
import {
  appendResponseMessages,
  createDataStreamResponse,
  streamText,
  type Message,
  type StreamTextOnFinishCallback,
  type ToolSet
} from "ai";
import type { IncomingMessage, OutgoingMessage } from "./types";
// import { env } from "cloudflare:workers";

const model = openai("gpt-4o-2024-11-20");
// Cloudflare AI Gateway
// const openai = createOpenAI({
//   apiKey: env.OPENAI_API_KEY,
//   baseURL: env.GATEWAY_BASE_URL,
// });

/**
 * Chat Agent implementation that handles real-time AI chat interactions
 */
type AgentState = {
  messages: { [sessionId: string]: Message[] } // session ID -> messages
  desktops: { [sessionId: string]: string } // session ID -> desktop
}

const decoder = new TextDecoder();

export class Chat extends AIChatAgent<Env, AgentState> {
  /**
   * Handles incoming chat messages and manages the response stream
   * @param onFinish - Callback function executed when streaming completes
   */

  initialState: AgentState = {
    messages: {},
    desktops: {},
  };

  private _broadcastMessage(message: OutgoingMessage, exclude?: string[]) {
    this.broadcast(JSON.stringify(message), exclude);
  }
  private async _try<T>(fn: () => T | Promise<T>) {
    try {
      return await fn();
    } catch (e) {
      throw this.onError(e);
    }
  }

  override async onMessage(connection: Connection, message: WSMessage) {
    console.log(message)
    const incomingMessage = JSON.parse(message.toString()) as IncomingMessage;
    if (incomingMessage.type === "cf_agent_use_chat_request") {
      if (
        incomingMessage.init.method === "POST"
      ) {
        const {
          // method,
          // keepalive,
          // headers,
          body // we're reading this
          //
          // // these might not exist?
          // dispatcher,
          // duplex
        } = incomingMessage.init;
        const { messages, data } = JSON.parse(body as string);
        const sessionId = data.annotations.sessionId;
        this._broadcastMessage(
          {
            messages,
            type: "cf_agent_chat_messages",
            sessionId
          },
          [connection.id]
        );

        this.setState({
          messages: {
            ...this.state.messages,
            [sessionId]: messages
          },
          desktops: {
            ...this.state.desktops,
            [sessionId]: ""
          }
        });

        const chatMessageId = incomingMessage.id;

        return this._try(async () => {
          const response = await this.chatMessageHandler(
            sessionId,
            async ({ response }) => {
              const finalMessages = appendResponseMessages({
                messages,
                responseMessages: response.messages
              });
              this.setState({
                messages: {
                  ...this.state.messages,
                  [sessionId]: finalMessages
                },
                desktops: {
                  ...this.state.desktops,
                  [sessionId]: ""
                }
              });
            },
          );

          if (response) {
            this._try(async () => {
              // @ts-expect-error TODO: fix this type error
              for await (const chunk of response.body!) {
                const body = decoder.decode(chunk);

                this._broadcastMessage({
                  body,
                  done: false,
                  id: incomingMessage.id,
                  type: "cf_agent_use_chat_response",
                  sessionId
                });
              }

              this._broadcastMessage({
                body: "",
                done: true,
                id: incomingMessage.id,
                type: "cf_agent_use_chat_response",
                sessionId
              });
            });
          } else {
            // Log a warning for observability
            console.warn(
              `[AIChatAgent] onChatMessage returned no response for chatMessageId: ${chatMessageId}`
            );
            // Send a fallback message to the client
            this._broadcastMessage(
              {
                body: "No response was generated by the agent.",
                done: true,
                id: incomingMessage.id,
                type: "cf_agent_use_chat_response",
                sessionId
              },
              [connection.id]
            );
          }
        });
      }

    } else if (incomingMessage.type === "cf_agent_chat_clear") {
      this.setState({
        messages: {},
        desktops: {},
      });
    }
  }

  override async onRequest(request: Request): Promise<Response> {
    return this._try(() => {
      const url = new URL(request.url);
      if (url.pathname.endsWith("/get-messages")) {
        console.log(this.state.messages)
        const sessionId = url.searchParams.get("sessionId") as string
        console.log(sessionId)
        const messages = (
          this.state.messages[sessionId] || []
        );
        console.log(messages)
        return Response.json(messages);
      }
      return super.onRequest(request);
    });
  }

  async chatMessageHandler(
    sessionId: string,
    onFinish: StreamTextOnFinishCallback<ToolSet>,
  ) {
    const reqId = `${sessionId}_${Date.now()}`;
    /* Fetch random data, this SHOULD NOT FAIL*/
    console.log(`[${reqId}] Fetching random data...`)
    await (await fetch("https://microsoftedge.github.io/Demos/json-dummy-data/64KB.json")).json();
    console.log(`[${reqId}] Random data fetched successfully!`)

    let desktop;
    if (this.state.desktops[sessionId]) {
      console.log(`[${reqId}] Connecting to existing desktop...`)
      desktop = await Sandbox.connect(this.state.desktops[sessionId]);
    } else {
      console.log(`[${reqId}] Creating desktop...`)
      desktop = await Sandbox.create("runable_computer_v4", {
        display: ":0",
        timeoutMs: 1_800_000,
        resolution: [640, 480],
        metadata: {
          id: sessionId,
        },
      });
    }
    console.log(`[${reqId}] Desktop created successfully!`)
    await Promise.all([
      desktop.files.write("/home/user/.token", crypto.randomUUID()),
      desktop.stream.start({
        requireAuth: true,
      }),
    ]);

    const authKey = desktop.stream.getAuthKey();
    const streamUrl = desktop.stream.getUrl({
      authKey,
    });
    this.setState({
      messages: {
        ...this.state.messages,
      },
      desktops: {
        ...this.state.desktops,
        [sessionId]: desktop.sandboxId
      }
    });
    console.log(`[${reqId}] Stream URL: ${streamUrl}`)
    // Create a streaming response that handles both text and tool outputs
    const dataStreamResponse = createDataStreamResponse({
      execute: async (dataStream) => {
        // Stream the AI response using GPT-4
        const result = streamText({
          model,
          system: `You are a helpful assistant that can do various tasks... 

${unstable_getSchedulePrompt({ date: new Date() })}

If the user asks to schedule a task, use the schedule tool to schedule the task.
`,
          messages: this.state.messages[sessionId] || [],
          onFinish,
          onError: (error) => {
            console.error(`[${reqId}] Error while streaming:`, error);
          },
          maxSteps: 10,
        });

        // Merge the AI response stream with tool execution outputs
        result.mergeIntoDataStream(dataStream);
      },
    });

    console.log(`[${reqId}] Data stream response created successfully!`)
    return dataStreamResponse;
  }
}

/**
 * Worker entry point that routes incoming requests to the appropriate handler
 */
export default {
  async fetch(request: Request, env: Env, _ctx: ExecutionContext) {
    const url = new URL(request.url);

    if (url.pathname === "/check-open-ai-key") {
      const hasOpenAIKey = !!process.env.OPENAI_API_KEY;
      return Response.json({
        success: hasOpenAIKey,
      });
    }
    if (!process.env.OPENAI_API_KEY) {
      console.error(
        "OPENAI_API_KEY is not set, don't forget to set it locally in .dev.vars, and use `wrangler secret bulk .dev.vars` to upload it to production"
      );
    }
    return (
      // Route the request to our agent or return 404 if not found
      (await routeAgentRequest(request, env)) ||
      new Response("Not found", { status: 404 })
    );
  },
} satisfies ExportedHandler<Env>;
